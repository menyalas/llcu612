{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Alayne Moody, LLCU 612, HW5</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The text I have chosen is <i>My Antonia</i> by Willa Cather, a novel about immigrants in the United States. While Project Gutenberg offers other examples of migration literature (that is, works by or about migrants), I chose \"My Antonia\" because it is a novel that I recently read. With a this close reading under my belt, I expected that my quantitative exploration of concordances and collocates would be especially meaningdful.</p>\n",
    "<p>Published in 1918, <i>My Antonia</i> is presented as a memoir of a friend of the author about a mutual childhood acquaintance, an immigrant girl by the Antonia. In the story, Cather's friend -- Jim Burton -- meets Antonia when they move to adjacent farms in Nebraska, Jim to live with his grandparents after the death of his parents, Antonia with her family after their emigration from Bohemia. Like Antonia, Jim is new to Nebraska, but his journey has only taken him from the eastern United States, and his grandparents are established and adept homesteaders. </p>\n",
    "<p>As the story unfolds, Cather presents -- through Jim -- an empathetic and somewhat heroic depiction of Antonia and immigrants more generally in the settling of the United States. <p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import, decode and place into an object variable the text. \n",
    "import urllib.request\n",
    "url = \"https://www.gutenberg.org/files/242/242-0.txt\"\n",
    "string = urllib.request.urlopen(url).read().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I identified the start and end points of the text by scrolling through the .txt file online, determining that the terms shown below were the ones that would work not only with <i>My Antonia</i> but with other Project Gutenberg offerings. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate the story by omitting the front and back matter, including copyright information.\n",
    "import os\n",
    "start = string.find(\"INTRODUCTION\")\n",
    "end = string.find(\"End of the Project Gutenberg EBook\")\n",
    "stringStory = string[start:end]\n",
    "#If one doesn't not exist, make a new folder \"called data\" and save the .txt file there. \n",
    "directory = \"data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "with open(\"data/cather01.txt\",\"w\") as f:\n",
    "    f.write(stringStory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTRODUCTION\r\n",
      "\r\n",
      "LAST summer I happened to be crossing the plains of Iowa in a season\r\n",
      "of intense heat, and it was my good fortune to have for a traveling\r\n",
      "companion James Quayle Burden--Jim Burden, as\n",
      "***\n",
      "d for us all that we can ever be. Now I understood\r\n",
      "that the same road was to bring us together again. Whatever we had\r\n",
      "missed, we possessed together the precious, the incommunicable past.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the first and last 200 characters of the story to ascertain that the above code worked correctly. \n",
    "print(stringStory[0:200])\n",
    "print(\"***\")\n",
    "print(stringStory[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INTRODUCTION', 'LAST', 'summer', 'I', 'happened', 'to', 'be', 'crossing', 'the', 'plains', 'of', 'Iowa', 'in', 'a', 'season', 'of', 'intense', 'heat', ',', 'and', 'it', 'was', 'my', 'good', 'fortune', 'to', 'have', 'for', 'a', 'traveling', 'companion', 'James', 'Quayle', 'Burden', '--', 'Jim', 'Burden', ',', 'as', 'we', 'still', 'call', 'him', 'in', 'the', 'West', '.', 'He', 'and', 'I']\n"
     ]
    }
   ],
   "source": [
    "#Break the story into word tokens and have a peek at what those look like. \n",
    "import nltk\n",
    "tokens = nltk.word_tokenize(stringStory)\n",
    "print(tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INTRODUCTION', 'LAST', 'summer', 'I', 'happened', 'to', 'be', 'crossing', 'the', 'plains', 'of', 'Iowa', 'in', 'a', 'season', 'of', 'intense', 'heat', 'and', 'it', 'was', 'my', 'good', 'fortune', 'to', 'have', 'for', 'a', 'traveling', 'companion', 'James', 'Quayle', 'Burden', 'Jim', 'Burden', 'as', 'we', 'still', 'call', 'him', 'in', 'the', 'West', 'He', 'and', 'I', 'are', 'old', 'friends', 'we']\n"
     ]
    }
   ],
   "source": [
    "#Remove punctuation marks using list comprehension technique.\n",
    "realTokens = [word for word in tokens if word[0].isalpha()]\n",
    "print(realTokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the  and   to    I    a   of  was   in  her that  had   he  his with  she   it   on  for   me    s were   at   as \n",
      "4097 3024 2250 1902 1673 1483 1407 1286 1021  884  838  799  756  725  681  591  588  583  565  497  496  486  476 \n"
     ]
    }
   ],
   "source": [
    "#Look at word frequencies\n",
    "freqRealTokens = nltk.FreqDist(realTokens)\n",
    "freqRealTokens.tabulate(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the  and   to    i    a   of  was   in   he  her  she that  had  his   it with   on  for   me  you   as   at were \n",
      "4491 3051 2262 1899 1707 1490 1413 1336 1186 1066 1002  937  841  811  731  729  629  596  567  565  539  528  498 \n"
     ]
    }
   ],
   "source": [
    "#Make all tokens lowercase to see if this changes the counts above.\n",
    "tokensLower = nltk.word_tokenize(stringStory.lower())\n",
    "realTokensLower = [word for word in tokensLower if word[0].isalpha()]\n",
    "freqRealTokensLower = nltk.FreqDist(realTokensLower)\n",
    "freqRealTokensLower.tabulate(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of types:  7820\n",
      "Number of tokens:  82760\n",
      "type/token ratio:  0.0944900918318028\n"
     ]
    }
   ],
   "source": [
    "#Measure Cather's vocabulary richness by calculating the ratio of unique words to total words. \n",
    "#To do this, we divide the total number of word forms (types) by the total number of words (tokens).\n",
    "print(\"Number of types: \", len(freqRealTokensLower))\n",
    "print(\"Number of tokens: \", len(realTokensLower))\n",
    "print(\"type/token ratio: \", len(freqRealTokensLower)/len(realTokensLower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To put Cather's type-token ratio of .09 in perspective, I looked for the TTRs reported for other novels. Andrew Piper shows on page 54 of <i>Enumerations</i> (2015) that the average TTRs for 1000 novels published between 1880 and 1930 is between .4 and .5, with James Joyce's <i>Ulysses</i> coming in at the upper limit. An examination of his dataset, available on GitHub, shows that four of Willa Cather's novels are included in the sample (<i>My Antonia</i> is not among them). The average TTR for Cather's works is between .43 and .45. The difference between Piper's figures and the one I found for <i>My Antonia</i> might have something to do with the way in which he standardized his measures to control for document length. For example, rather than considering entire texts, he calculated TTRs for 1000-word samples. Given the difference between Piper's results and mine, I investigated further and found that on page 98 of <i>Literature in the Digital Age</i> (2016), Adam Hammond reports TTR scores of .099 and .126 for four bestsellers from 1927, using a different method of standardization (that is, much larger sample sizes). Hammond's scores are closer to the value I found for <i>My Antonia</i> (1918). Furthermore, he reports a TTR of .163 for Joyce's <i>Ulysses</i>, which is about .33 the magnitude of the TTR reported by Piper. Applying this multiplier to the Cather values found by Piper and myself do not, however, bring them into alignment. To be specific, multiplying .44 by .33 yields .15, which is still considerably different from the .09 value that I found for <i>My Antonia</i>.  Further study is needed to explain the disparity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "#Import and print stopwords list\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "print(sorted(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample words:  ['last', 'summer', 'i', 'happened', 'to', 'be', 'crossing', 'the', 'plains']\n",
      "sample words not in stopwords list:  ['last', 'summer', 'happened', 'crossing', 'plains']\n"
     ]
    }
   ],
   "source": [
    "#Test stopwords\n",
    "print(\"sample words: \", realTokensLower[1:10])\n",
    "print(\"sample words not in stopwords list: \", [word for word in realTokensLower[1:10] if not word in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   like     one antonia    said   could  little   would    came     old      us   never    went    mrs.    lena \n",
      "    347     295     282     258     232     231     219     206     203     201     199     192     187     179 \n"
     ]
    }
   ],
   "source": [
    "#show most frequent words minus stopwords\n",
    "contentRealTokensLower = [word for word in realTokensLower if word not in stopwords]\n",
    "freqContentRealTokensLower = nltk.FreqDist(contentRealTokensLower)\n",
    "freqContentRealTokensLower.tabulate(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 282 matches:\n",
      "n on paper all that I remembered of Antonia if he would do the same . We might \n",
      "ly what I most wanted to know about Antonia . He had had opportunities that I ,\n",
      "ed it last night -- the thing about Antonia , ” he said . “ Now , what about yo\n",
      "herself and myself and other people Antonia ’ s name recalls to me . I suppose \n",
      "it to me . NOTE : The Bohemian name Antonia is strongly accented on the first s\n",
      " . The Shimerdas I I FIRST HEARD OF Antonia on what seemed to me an interminabl\n",
      " . The little girl was pretty , but Antonia -- they accented the name thus , st\n",
      " was translating for Mr. Shimerda , Antonia came up to me and held out her hand\n",
      "-tops , I pointed toward them , and Antonia laughed and squeezed my hand as if \n",
      "skirts were blown out before them . Antonia seemed to like it ; she held her li\n"
     ]
    }
   ],
   "source": [
    "#Show concordances for a character (Antonia).\n",
    "text = nltk.Text(tokens)\n",
    "text.concordance(\"antonia\", lines=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In just the first 10 instances of the term \"Antonia,\" we learn -- as is shown throughout the story -- that the main character is perceived by the narrator as an alluring and respectable figure. She is attractive (\"pretty\"), exotic (the sound of her name is \"accented\"), warm (she is someone who \"laughed\" and \"squeezed my hand\") and robust (she \"seemed to like\" how the wind blew her skirt before her). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Hawk; Mrs. Harling; Mrs. Shimerda; Mr. Shimerda; Lena Lingard;\n",
      "Tiny Soderball; could see; New York; Mrs. Gardener; old man\n"
     ]
    }
   ],
   "source": [
    "#Approach #1 for finding collocations.\n",
    "text.collocations(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seemed to work for bigrams but the \"window_size\" argument described in the <a href=\"http://www.nltk.org/api/nltk.html#nltk.text.Text.collocations\">NLTK documentaton</a> did not work. I therefore used a second approach, adapted from the instructions provided <a href=\"http://www.nltk.org/howto/collocations.html\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams:\n",
      "[(('mrs.', 'harling'), 0.0015016925857110133), (('mrs.', 'shimerda'), 0.0013744305021761816)]\n",
      "***\n",
      "Trigrams:\n",
      "[(('said', 'mrs.', 'harling'), 0.00015271450024179797), (('three', 'bohemian', 'marys'), 0.00012726208353483164)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "#Bigrams\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "word_fd = nltk.FreqDist(contentRealTokensLower)\n",
    "bigram_fd = nltk.FreqDist(nltk.bigrams(contentRealTokensLower))\n",
    "finderBG = BigramCollocationFinder(word_fd, bigram_fd)\n",
    "\n",
    "#Trigrams\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finderTG = TrigramCollocationFinder.from_words(contentRealTokensLower)\n",
    "\n",
    "print(\"Bigrams:\")\n",
    "print(finderBG.score_ngrams(bigram_measures.raw_freq)[1:3])\n",
    "print(\"***\")\n",
    "print(\"Trigrams:\")\n",
    "print(finderTG.score_ngrams(trigram_measures.raw_freq)[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that the code appears to work, but it would be more helpful to see the bigrams and trigrams in order of decreasing frequency, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antonia', 'said'),\n",
       " ('black', 'hawk'),\n",
       " ('could', 'see'),\n",
       " ('lena', 'lingard'),\n",
       " ('mr.', 'shimerda'),\n",
       " ('mrs.', 'burden'),\n",
       " ('mrs.', 'cutter'),\n",
       " ('mrs.', 'harling'),\n",
       " ('mrs.', 'shimerda'),\n",
       " ('old', 'man')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the top ten bigrams\n",
    "sorted(finderBG.nbest(bigram_measures.raw_freq, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our top ten bigrams are mostly characters, along with \"Black Hawk\" (the name of the town near in which much of the story is set). It is unclear to whom \"old man\" refers, as there are several mature men in the story. It is interesting, however, that this term is more common than \"old woman,\" given that there are at least as many old women as men among the main characters (for example, Antonia's father and another prominant male character die early in the story whereas most of the female characters survive for the duration). One possibility is that this bigram is prominent becomes it combines the occurences of \"old man\" characters with references to the state of the narrator at the time he offers his memoir. That is, he is an older man remembering a person from his childhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bench', 'behind', 'stove'),\n",
       " ('black', 'hawk', 'money-lender'),\n",
       " ('black', 'hawk', 'road'),\n",
       " ('could', 'see', 'nothing'),\n",
       " ('danish', 'laundry', 'girls'),\n",
       " ('old', 'mr.', 'shimerda'),\n",
       " ('one', 'could', 'see'),\n",
       " ('said', 'mrs.', 'harling'),\n",
       " ('three', 'bohemian', 'marys'),\n",
       " ('threw', 'arms', 'around')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the top ten trigrams\n",
    "sorted(finderTG.nbest(trigram_measures.raw_freq, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trigrams reveal more minute details about setting, one important place being the road that links the farms belonging to the narrator's grandparents and Antonia's family with the nearest town, Black Hawk. An interesting aspect of <i>My Antonia</i> is that the female author tells the story through the perspective of a male narrator. However, this male character is a boy who is looked after by or otherwise interacts with mostly women (e.g., his grandmother, Antonia, Mrs Harling, the Danish laundry girls). As a result, much of the action of the story occurs in places associated with women's work (e.g., the bench behind the kitchen). The single top-10 trigram referring to a male character is \"black hawk money-lender,\" a character who takes advantage of Antonia and other immigrants in the story and who ultimately commits murder-suicide to prevent his wife and her family from inheriting his wealth."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
