{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = \"https://www.gutenberg.org/files/242/242-0.txt\"\n",
    "string = urllib.request.urlopen(url).read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "start = string.find(\"INTRODUCTION\")\n",
    "end = string.find(\"End of the Project Gutenberg EBook\")\n",
    "stringStory = string[start:end]\n",
    "directory = \"llcu612/data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "with open(\"data/cather01.txt\",\"w\") as f:\n",
    "    f.write(stringStory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/cather01.txt\", \"r\") as f:\n",
    "    stringStory = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTRODUCTION\n",
      "\n",
      "LAST summer I happened to be crossing the plains of Iowa in a season\n",
      "of intense heat, and it was my good fortune to have for a traveling\n",
      "companion James Quayle Burden--Jim Burden, as we \n",
      "***\n",
      "etermined for us all that we can ever be. Now I understood\n",
      "that the same road was to bring us together again. Whatever we had\n",
      "missed, we possessed together the precious, the incommunicable past.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(stringStory[0:200])\n",
    "print(\"***\")\n",
    "print(stringStory[-200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tokenization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTRODUCTION',\n",
       " 'LAST',\n",
       " 'summer',\n",
       " 'I',\n",
       " 'happened',\n",
       " 'to',\n",
       " 'be',\n",
       " 'crossing',\n",
       " 'the',\n",
       " 'plains']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(stringStory)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INTRODUCTION', 'LAST', 'summer', 'I', 'happened', 'to', 'be', 'crossing', 'the', 'plains', 'of', 'Iowa', 'in', 'a', 'season', 'of', 'intense', 'heat', ',', 'and', 'it', 'was', 'my', 'good', 'fortune', 'to', 'have', 'for', 'a', 'traveling', 'companion', 'James', 'Quayle', 'Burden', '--', 'Jim', 'Burden', ',', 'as', 'we', 'still', 'call', 'him', 'in', 'the', 'West', '.', 'He', 'and', 'I', 'are', 'old', 'friends', '--', 'we', 'grew', 'up', 'together', 'in', 'the', 'same', 'Nebraska', 'town', '--', 'and', 'we', 'had', 'much', 'to', 'say', 'to', 'each', 'other', '.', 'While', 'the', 'train', 'flashed', 'through', 'never-ending', 'miles', 'of', 'ripe', 'wheat', ',', 'by', 'country', 'towns', 'and', 'bright-flowered', 'pastures', 'and', 'oak', 'groves', 'wilting', 'in', 'the', 'sun', ',', 'we'] (for loop technique)\n",
      "['INTRODUCTION', 'LAST', 'summer', 'I', 'happened', 'to', 'be', 'crossing', 'the', 'plains', 'of', 'Iowa', 'in', 'a', 'season', 'of', 'intense', 'heat', ',', 'and', 'it', 'was', 'my', 'good', 'fortune', 'to', 'have', 'for', 'a', 'traveling', 'companion', 'James', 'Quayle', 'Burden', '--', 'Jim', 'Burden', ',', 'as', 'we', 'still', 'call', 'him', 'in', 'the', 'West', '.', 'He', 'and', 'I', 'are', 'old', 'friends', '--', 'we', 'grew', 'up', 'together', 'in', 'the', 'same', 'Nebraska', 'town', '--', 'and', 'we', 'had', 'much', 'to', 'say', 'to', 'each', 'other', '.', 'While', 'the', 'train', 'flashed', 'through', 'never-ending', 'miles', 'of', 'ripe', 'wheat', ',', 'by', 'country', 'towns', 'and', 'bright-flowered', 'pastures', 'and', 'oak', 'groves', 'wilting', 'in', 'the', 'sun', ',', 'we'] (list comprehension technique)\n"
     ]
    }
   ],
   "source": [
    "loopList = []\n",
    "for word in tokens[:100]:\n",
    "    loopList.append(word)\n",
    "print(loopList,\"(for loop technique)\")\n",
    "print([word for word in tokens[:100]], \"(list comprehension technique)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INTRODUCTION', 'LAST', 'summer', 'I', 'happened', 'to', 'be', 'crossing', 'the', 'plains', 'of', 'Iowa', 'in', 'a', 'season', 'of', 'intense', 'heat', 'and', 'it', 'was', 'my', 'good', 'fortune', 'to', 'have', 'for', 'a', 'traveling', 'companion', 'James', 'Quayle', 'Burden', 'Jim', 'Burden', 'as', 'we', 'still', 'call', 'him', 'in', 'the', 'West', 'He', 'and', 'I', 'are', 'old', 'friends', 'we', 'grew', 'up', 'together', 'in', 'the', 'same', 'Nebraska', 'town', 'and', 'we', 'had', 'much', 'to', 'say', 'to', 'each', 'other', 'While', 'the', 'train', 'flashed', 'through', 'never-ending', 'miles', 'of', 'ripe', 'wheat', 'by', 'country', 'towns', 'and', 'bright-flowered', 'pastures', 'and', 'oak', 'groves', 'wilting', 'in', 'the', 'sun', 'we']\n"
     ]
    }
   ],
   "source": [
    "print([word for word in tokens[:100] if word[0].isalpha()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Word Frequencies</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 8311 samples and 82760 outcomes>\n"
     ]
    }
   ],
   "source": [
    "realTokens = [word for word in tokens if word[0].isalpha()]\n",
    "freqRealTokens = nltk.FreqDist(realTokens)\n",
    "print(freqRealTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the  and   to    I    a   of  was   in  her that  had   he  his with  she \n",
      "4097 3024 2250 1902 1673 1483 1407 1286 1021  884  838  799  756  725  681 \n"
     ]
    }
   ],
   "source": [
    "freqRealTokens.tabulate(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "introduction         last       summer            i     happened \n",
      "           1            1            1            1            1 \n"
     ]
    }
   ],
   "source": [
    "tokensLower = nltk.word_tokenize(stringStory.lower())\n",
    "realTokensLower = [word for word in tokensLower[:5] if word[0].isalpha()]\n",
    "freqRealTokensLower = nltk.FreqDist(realTokensLower)\n",
    "freqRealTokensLower.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokensLower = nltk.word_tokenize(stringStory.lower())\n",
    "realTokensLower = [word for word in tokensLower if word[0].isalpha()]\n",
    "freqRealTokensLower = nltk.FreqDist(realTokensLower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of types:  7820\n",
      "Number of tokens:  82760\n",
      "type/token ratio:  0.0944900918318028\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of types: \", len(freqRealTokensLower))\n",
    "print(\"Number of tokens: \", len(realTokensLower))\n",
    "print(\"type/token ratio: \", len(freqRealTokensLower)/len(realTokensLower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 7820 samples and 82760 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(freqRealTokensLower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: It seems like both of these values are contained in the object. Is there no automatic way to calculate this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the  and   to    i    a   of  was   in   he  her  she that  had  his   it with   on  for   me  you \n",
      "4491 3051 2262 1899 1707 1490 1413 1336 1186 1066 1002  937  841  811  731  729  629  596  567  565 \n"
     ]
    }
   ],
   "source": [
    "freqRealTokensLower.tabulate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "print(sorted(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample words:  ['last', 'summer', 'i', 'happened', 'to', 'be', 'crossing', 'the', 'plains']\n",
      "sample words no in stopwords list:  ['last', 'summer', 'happened', 'crossing', 'plains']\n"
     ]
    }
   ],
   "source": [
    "print(\"sample words: \", realTokensLower[1:10])\n",
    "print(\"sample words no in stopwords list: \", [word for word in realTokensLower[1:10] if not word in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   like     one antonia    said   could  little   would    came     old      us   never    went    mrs.    lena \n",
      "    347     295     282     258     232     231     219     206     203     201     199     192     187     179 \n"
     ]
    }
   ],
   "source": [
    "contentRealTokensLower = [word for word in realTokensLower if word not in stopwords]\n",
    "freqContentRealTokensLower = nltk.FreqDist(contentRealTokensLower)\n",
    "freqContentRealTokensLower.tabulate(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building a Simple Concordance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LAST', 'summer', 'I', 'happened', 'to', 'be', 'crossing', 'the', 'plains', 'of', 'Iowa', 'in', 'a', 'season', 'of', 'intense', 'heat', ',', 'and', 'it', 'was', 'my', 'good', 'fortune', 'to', 'have', 'for', 'a', 'traveling', 'companion', 'James', 'Quayle', 'Burden', '--', 'Jim', 'Burden', ',', 'as', 'we', 'still', 'call', 'him', 'in', 'the', 'West', '.', 'He', 'and', 'I', 'are', 'old', 'friends', '--', 'we', 'grew', 'up', 'together', 'in', 'the', 'same', 'Nebraska', 'town', '--', 'and', 'we', 'had', 'much', 'to', 'say', 'to', 'each', 'other', '.', 'While', 'the', 'train', 'flashed', 'through', 'never-ending', 'miles', 'of', 'ripe', 'wheat', ',', 'by', 'country', 'towns', 'and', 'bright-flowered', 'pastures', 'and', 'oak', 'groves', 'wilting', 'in', 'the', 'sun', ',', 'we']\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(text[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 25 matches:\n",
      "n on paper all that I remembered of Antonia if he would do the same . We might \n",
      "ly what I most wanted to know about Antonia . He had had opportunities that I ,\n",
      "ed it last night -- the thing about Antonia , ” he said . “ Now , what about yo\n",
      "herself and myself and other people Antonia ’ s name recalls to me . I suppose \n",
      "it to me . NOTE : The Bohemian name Antonia is strongly accented on the first s\n",
      " . The Shimerdas I I FIRST HEARD OF Antonia on what seemed to me an interminabl\n",
      " . The little girl was pretty , but Antonia -- they accented the name thus , st\n",
      " was translating for Mr. Shimerda , Antonia came up to me and held out her hand\n",
      "-tops , I pointed toward them , and Antonia laughed and squeezed my hand as if \n",
      "skirts were blown out before them . Antonia seemed to like it ; she held her li\n"
     ]
    }
   ],
   "source": [
    "text.concordance(\"Antonia\", lines=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Collocations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Hawk; Mrs. Harling; Mrs. Shimerda; Mr. Shimerda; Lena Lingard;\n",
      "Tiny Soderball; could see; New York; Mrs. Gardener; old man\n"
     ]
    }
   ],
   "source": [
    "text.collocations(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antonia', 'said'),\n",
       " ('black', 'hawk'),\n",
       " ('could', 'see'),\n",
       " ('lena', 'lingard'),\n",
       " ('mr.', 'shimerda'),\n",
       " ('mrs.', 'burden'),\n",
       " ('mrs.', 'cutter'),\n",
       " ('mrs.', 'harling'),\n",
       " ('mrs.', 'shimerda'),\n",
       " ('old', 'man'),\n",
       " ('young', 'man')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "word_fd = nltk.FreqDist(contentRealTokensLower)\n",
    "bigram_fd = nltk.FreqDist(nltk.bigrams(contentRealTokensLower))\n",
    "finder = BigramCollocationFinder(word_fd, bigram_fd)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "sorted(finder.above_score(bigram_measures.raw_freq, 16.0 / len(tuple(nltk.bigrams(contentRealTokensLower)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antonia', 'said'),\n",
       " ('black', 'hawk'),\n",
       " ('could', 'see'),\n",
       " ('lena', 'lingard'),\n",
       " ('mr.', 'shimerda'),\n",
       " ('mrs.', 'burden'),\n",
       " ('mrs.', 'cutter'),\n",
       " ('mrs.', 'harling'),\n",
       " ('mrs.', 'shimerda'),\n",
       " ('old', 'man')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(finder.nbest(bigram_measures.raw_freq, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bench', 'behind', 'stove'),\n",
       " ('black', 'hawk', 'money-lender'),\n",
       " ('black', 'hawk', 'road'),\n",
       " ('could', 'see', 'nothing'),\n",
       " ('danish', 'laundry', 'girls'),\n",
       " ('old', 'mr.', 'shimerda'),\n",
       " ('one', 'could', 'see'),\n",
       " ('said', 'mrs.', 'harling'),\n",
       " ('three', 'bohemian', 'marys'),\n",
       " ('threw', 'arms', 'around')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder = TrigramCollocationFinder.from_words(contentRealTokensLower)\n",
    "scored = finder.score_ngrams(trigram_measures.raw_freq)\n",
    "sorted(finder.nbest(trigram_measures.raw_freq, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
